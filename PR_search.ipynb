{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cc5969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "from IPython import display  # needed to plot training statistics\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import heatmap\n",
    "\n",
    "import pylab as pl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c85ec0",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cca78fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = os.path.abspath('')\n",
    "\n",
    "pheno = \"diab\"\n",
    "\n",
    "# paths\n",
    "## input paths\n",
    "\n",
    "vcf_path = f\"./data/ext_prs.90k.{pheno}.vcf\"\n",
    "ordered_target_path = f\"./data/phenotype.{pheno}.ordered\"\n",
    "ordered_covariates_path = f\"./data/cov.{pheno}.ordered\"\n",
    "\n",
    "## output paths\n",
    "target_output_path = os.path.join(main_path, \"data\", f\"target_{pheno}.csv\")\n",
    "transposed_feature_matrix_path = os.path.join(\n",
    "    main_path, \"data\", f\"feature_matrix_{pheno}.csv\")\n",
    "feature_cov_path = os.path.join(\n",
    "    main_path, \"data\", f\"feature_cov_matrix_{pheno}.csv\")\n",
    "feature_cov_hla_path = os.path.join(\n",
    "    main_path, \"data\", f\"feature_cov_hla_matrix_{pheno}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07db281",
   "metadata": {
    "id": "c37df085"
   },
   "source": [
    "# Model (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a105e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'run': 409,\n",
    " 'overall_epochs': 200,\n",
    " 'lr': 0.001,\n",
    " 'run_id': 1684699473,\n",
    " 'bn_momentum': 0.9,\n",
    " 'first_dropout': 0.9,\n",
    " 'other_dropouts': 0.9,\n",
    " 'lin1_output': 100,\n",
    " 'lin2_output': 50,\n",
    " 'lin3_output': 10,\n",
    " 'test_ROC_AUC': 0.8387424608828513,\n",
    " 'test_recall': 0.6956521739130435,\n",
    " 'test_precision': 0.022408963585434174,\n",
    " 'confusion_matrix': {'TP': 12523.0, 'TN': 48.0, 'FP': 2094.0, 'FN': 21.0},\n",
    " 'test_accuracy': 0.8559852921149393,\n",
    " 'test_PR_AUC': 0.04604731954223416,\n",
    " 'F1-score': 0.04341926729986431,\n",
    " 'best_epochs': 94}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d85272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model info\n",
    "bn_momentum = params[\"bn_momentum\"]\n",
    "first_dropout = params[\"first_dropout\"]\n",
    "other_dropouts = params[\"other_dropouts\"]\n",
    "lin1_output = params[\"lin1_output\"]\n",
    "lin2_output = params[\"lin2_output\"]\n",
    "lin3_output = params[\"lin3_output\"]\n",
    "\n",
    "\n",
    "batch_size = 4096\n",
    "learning_rate = params[\"lr\"]\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce02a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopper\n",
    "min_delta = 0.08\n",
    "patience = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4be8cbf",
   "metadata": {
    "id": "efa1f81a"
   },
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a54d17",
   "metadata": {
    "id": "408810c9"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b92f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70b30b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(target_output_path, header=None)\n",
    "print(df.shape)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.3, stratify=df, random_state=5)\n",
    "train_index = train.index\n",
    "test_index = test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c529d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429c4b10",
   "metadata": {
    "id": "3O5ESqvev5nv"
   },
   "outputs": [],
   "source": [
    "class PRS_Dataset(Dataset):\n",
    "\n",
    "    \"\"\" \n",
    "    Loads features and tatget. take = n -> take *first* n entries for dataset (if train = True);\n",
    "    take *last* n entries for dataset (if train = False) \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x_path, y_path, take, train):\n",
    "\n",
    "        y = np.loadtxt(y_path, delimiter=',', dtype=np.float32) # тут увеличил размер\n",
    "        print(y.shape)\n",
    "        x = np.loadtxt(x_path, delimiter=',', dtype=np.float32)\n",
    "        \n",
    "        if train:\n",
    "            x = x[train_index]\n",
    "            y = y[train_index]\n",
    "\n",
    "\n",
    "        else:\n",
    "            x = x[test_index]\n",
    "            y = y[test_index]\n",
    "\n",
    "        self.x_data = torch.from_numpy(x).to(torch.float32)\n",
    "        self.y_data = torch.from_numpy(y).to(torch.float32)\n",
    "        self.y_data = self.y_data.unsqueeze(1)\n",
    "        print(f\"x_data {self.x_data.shape}\")\n",
    "        print(f\"y_data {self.y_data.shape}\")\n",
    "\n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return len(self.y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6069b1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"gen_cov_hla\"\n",
    "\n",
    "if mode == \"gen\":\n",
    "    feature_path = transposed_feature_matrix_path\n",
    "elif mode == \"cov\":\n",
    "    feature_path = ordered_covariates_path\n",
    "elif mode == \"gen_cov\":\n",
    "    feature_path = feature_cov_path\n",
    "elif mode == \"gen_cov_hla\":\n",
    "    feature_path = feature_cov_hla_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23144b3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "de73ed98",
    "outputId": "5e5393fd-92f6-4675-9dd6-f411a2cee8f3"
   },
   "outputs": [],
   "source": [
    "train_dataset = PRS_Dataset(feature_path, target_output_path,\n",
    "                            take=0.7, train=True)\n",
    "test_dataset = PRS_Dataset(feature_path, target_output_path,\n",
    "                           take=0.3,  train=False)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10749abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = iter(test_loader)\n",
    "x_batch, y_batch = next(example)\n",
    "input_size = x_batch.shape[1]\n",
    "print(x_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae67af1b",
   "metadata": {
    "id": "e0518698"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfba332",
   "metadata": {
    "id": "83af8400"
   },
   "outputs": [],
   "source": [
    "class P1(nn.Module):\n",
    "    def __init__(self, input_size, bn_momentum=0.9, first_dropout=0.9, other_dropouts=0.9,\n",
    "                 lin1_output=1000, lin2_output=250, lin3_output=50):\n",
    "        super(P1, self).__init__()\n",
    "        self.lin1 = nn.Linear(input_size, lin1_output)\n",
    "        self.bn1 = nn.BatchNorm1d(lin1_output, momentum=bn_momentum)\n",
    "        self.lin2 = nn.Linear(lin1_output, lin2_output)\n",
    "        self.bn2 = nn.BatchNorm1d(lin2_output, momentum=bn_momentum)\n",
    "\n",
    "        self.lin3 = nn.Linear(lin2_output, lin3_output)\n",
    "        self.bn3 = nn.BatchNorm1d(lin3_output, momentum=bn_momentum)\n",
    "\n",
    "        self.lin4 = nn.Linear(lin3_output, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.dropout_first = nn.Dropout(p=first_dropout)\n",
    "        self.dropout_other = nn.Dropout(p=other_dropouts)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.lin1(X)\n",
    "        X = self.relu(X)\n",
    "        X = self.bn1(X)\n",
    "        X = self.dropout_first(X)\n",
    "\n",
    "        X = self.lin2(X)\n",
    "        X = self.relu(X)\n",
    "        X = self.bn2(X)\n",
    "        X = self.dropout_other(X)\n",
    "\n",
    "        X = self.lin3(X)\n",
    "        X = self.relu(X)\n",
    "        X = self.bn3(X)\n",
    "\n",
    "        X = self.dropout_other(X)\n",
    "\n",
    "        X = self.lin4(X)\n",
    "        X = self.sigmoid(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3153917f",
   "metadata": {
    "id": "ee7c2511"
   },
   "outputs": [],
   "source": [
    "model = P1(input_size, bn_momentum=bn_momentum,\n",
    "               first_dropout=first_dropout, other_dropouts=other_dropouts,\n",
    "               lin1_output=lin1_output, lin2_output=lin2_output,\n",
    "               lin3_output=lin3_output).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCELoss()\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer,\n",
    "                                            T_0=10,  # Number of iterations for the first restart\n",
    "                                            T_mult=1,  # A factor increases TiTi after a restart\n",
    "                                            eta_min=1e-4)  # Minimum learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20332705",
   "metadata": {
    "id": "32560b20"
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbfcc72",
   "metadata": {
    "id": "VJkdjqgP8lwR"
   },
   "outputs": [],
   "source": [
    "def plot_stats(loss_history, auc_history):\n",
    "    \"\"\"Plot loss and ROC AUC in jupyter notebook\"\"\"\n",
    "\n",
    "    fig, (ax1, ax2) = pl.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # loss\n",
    "    training_loss = loss_history['train']\n",
    "    test_loss = loss_history['test']\n",
    "\n",
    "    epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "    ax1.plot(epoch_count, training_loss, '-r')\n",
    "    ax1.plot(epoch_count, test_loss, '-b')\n",
    "    ax1.legend(['Training loss', 'Test loss'])\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "\n",
    "    # auc\n",
    "    training_auc = auc_history['train']\n",
    "    test_auc = auc_history['test']\n",
    "\n",
    "    ax2.plot(epoch_count, training_auc, '-r')\n",
    "    ax2.plot(epoch_count, test_auc, '-b')\n",
    "    ax2.legend(['Training ROC AUC', 'Test ROC AUC'])\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('ROC AUC')\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(pl.gcf())\n",
    "    #time.sleep(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1c5809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves(cutoff, curves, current_params):\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "    # PR curve\n",
    "    ax1.plot(curves['PR']['recall'], curves['PR']['precision'])\n",
    "    ax1.title.set_text('Precision-Recall Curve')\n",
    "    ax1.set_ylabel('Precision')\n",
    "    ax1.set_xlabel('Recall')\n",
    "\n",
    "    # ROC curve\n",
    "    ax2.plot(curves['ROC']['false_positive_rate'], curves['ROC']\n",
    "             ['true_positive_rate'], label='AUC = %0.2f' % current_params['test_ROC_AUC'])\n",
    "    ax2.title.set_text('ROC Curve')\n",
    "    ax2.set_ylabel('True Positive Rate')\n",
    "    ax2.set_xlabel('False Positive Rate')\n",
    "    ax2.legend(loc = 'lower right')\n",
    "\n",
    "    # confusion matrix\n",
    "    conf_matrix = np.array(([current_params['confusion_matrix']['TP'],\n",
    "                                     current_params['confusion_matrix']['FP']],\n",
    "                                   [current_params['confusion_matrix']['FN'],\n",
    "                                   current_params['confusion_matrix']['TN']]))\n",
    "    \n",
    "    \n",
    "\n",
    "    ax4 = heatmap(conf_matrix, annot=True, fmt=\".1f\")\n",
    "    ax4.set(xlabel=\"Predicted Label\", ylabel=\"True Label\")\n",
    "    ax4.title.set_text('Confusion matrix')\n",
    "\n",
    "    \n",
    "    # model info\n",
    "    text = f\"Cutoff: {cutoff}\"\n",
    "        \n",
    "    ax3.text(0, 0.5, text, ha='left')\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    dir_path = f\"./figures/PR_test\"\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.mkdir(dir_path)\n",
    "    fp = f\"{dir_path}/PR_cutoff_{cutoff:.2f}.jpg\"\n",
    "    fig.savefig(fp, dpi=300)\n",
    "            \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d52dc6",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ed4dd3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9c89869b",
    "outputId": "aea69957-6f2a-4a53-de53-cbcbc6752627"
   },
   "outputs": [],
   "source": [
    "auc_history = {'train': [], 'test': []}\n",
    "aucs = {'train': [], 'test': []}\n",
    "loss_history = {'train': [], 'test': []}\n",
    "losses = {'train': [], 'test': []}\n",
    "best_test_auc = 0  # ищем лучший auc по эпохам\n",
    "best_epoch = None  # ищем лучшую эпоху\n",
    "best_model = None\n",
    "\n",
    "early_stopper = EarlyStopper(patience=patience, min_delta=min_delta)\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        # forward pass\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        pred = model(x_batch)\n",
    "        loss = criterion(pred, y_batch)\n",
    "        losses['train'].append(np.mean(loss.detach().cpu().numpy()))\n",
    "        aucs['train'].append(np.mean(roc_auc_score(\n",
    "            y_batch.detach().cpu().numpy(), pred.detach().cpu().numpy())))\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # check performance on test\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_example = iter(test_loader)\n",
    "        x_test, y_test = next(test_example)\n",
    "        x_test = x_test.to(device)\n",
    "        y_test = y_test.to(device)\n",
    "        pred_test = model(x_test)\n",
    "        loss = criterion(pred_test, y_test)\n",
    "        losses['test'].append(np.mean(loss.detach().cpu().numpy()))\n",
    "        aucs['test'].append(np.mean(roc_auc_score(\n",
    "            y_test.detach().cpu().numpy(), pred_test.detach().cpu().numpy())))\n",
    "\n",
    "    # scheduler step\n",
    "    scheduler.step()\n",
    "\n",
    "    # plot statistics\n",
    "    loss_history['train'].append(sum(losses['train'])/len(losses['train']))\n",
    "    loss_history['test'].append(sum(losses['test'])/len(losses['test']))\n",
    "    test_loss = sum(losses['test'])/len(losses['test'])\n",
    "    losses = {'train': [], 'test': []}\n",
    "    auc_history['train'].append(sum(aucs['train'])/len(aucs['train']))\n",
    "    auc_history['test'].append(sum(aucs['test'])/len(aucs['test']))\n",
    "    \n",
    "    curr_test_auc = sum(aucs['test'])/len(aucs['test'])\n",
    "    \n",
    "    aucs = {'train': [], 'test': []}\n",
    "\n",
    "    if curr_test_auc > best_test_auc:  # current best model\n",
    "        best_test_auc = curr_test_auc\n",
    "        best_epoch = epoch\n",
    "        best_model = model.state_dict()\n",
    "\n",
    "    \n",
    "    #if epoch%10 == 0:\n",
    "    #    plot_stats(loss_history, auc_history)   \n",
    "    \n",
    "    # early stopper\n",
    "    if early_stopper.early_stop(test_loss):             \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cca973",
   "metadata": {},
   "source": [
    "# PR on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4baa95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_values = [round(0.01*i, 2) for i in range(1, 100, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e215688",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_search = []\n",
    "\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "\n",
    "for i in tqdm(range(len(cutoff_values))):\n",
    "    cutoff = cutoff_values[i]\n",
    "\n",
    "    overall_pred_test = []\n",
    "    overall_pred_test_class = []\n",
    "    overall_y_test = []\n",
    "    ovarall_confmatrix = np.zeros((2, 2))\n",
    "    current_params = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_test, y_test in test_loader:\n",
    "            x_test = x_test.to(device)\n",
    "            y_test = y_test.cpu().numpy()\n",
    "            pred_test = model(x_test).detach().cpu().numpy()\n",
    "\n",
    "            pred_test_class = np.copy(pred_test)\n",
    "           # print(pred_test_class>cutoff)\n",
    "\n",
    "            pred_test_class[pred_test_class > cutoff] = 1\n",
    "            pred_test_class[pred_test_class <= cutoff] = 0\n",
    "\n",
    "            # append predicts\n",
    "            overall_y_test += list(y_test.flatten())\n",
    "            overall_pred_test += list(pred_test.flatten())\n",
    "            overall_pred_test_class += list(pred_test_class.flatten())\n",
    "\n",
    "    # collect metrics\n",
    "    overall_y_test = np.array(overall_y_test).reshape(-1, 1)\n",
    "    overall_pred_test = np.array(overall_pred_test).reshape(-1, 1)\n",
    "    overall_pred_test_class = (\n",
    "        np.array(overall_pred_test_class).reshape(-1, 1))\n",
    "\n",
    "    ovarall_confmatrix = confusion_matrix(\n",
    "        overall_y_test, overall_pred_test_class)\n",
    "\n",
    "    current_params['cutoff'] = cutoff\n",
    "    current_params['test_ROC_AUC'] = roc_auc_score(\n",
    "        overall_y_test, overall_pred_test)\n",
    "    current_params['test_recall'] = recall_score(\n",
    "        overall_y_test, overall_pred_test_class)\n",
    "    current_params['test_precision'] = precision_score(\n",
    "        overall_y_test, overall_pred_test_class, zero_division=0)\n",
    "    conf_matrix = {'TP': int(ovarall_confmatrix[0][0]),\n",
    "                   'TN': int(ovarall_confmatrix[1][1]),\n",
    "                   'FP': int(ovarall_confmatrix[0][1]),\n",
    "                   'FN': int(ovarall_confmatrix[1][0])}\n",
    "    current_params['confusion_matrix'] = conf_matrix\n",
    "\n",
    "    current_params['test_accuracy'] = accuracy_score(\n",
    "        overall_y_test, overall_pred_test_class)\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(\n",
    "        overall_y_test, overall_pred_test)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    current_params['test_PR_AUC'] = pr_auc\n",
    "\n",
    "    current_params['F1-score'] = f1_score(overall_y_test,\n",
    "                                          overall_pred_test_class)\n",
    "\n",
    "    curves = {'ROC': {}, 'PR': {}}\n",
    "    curves['ROC']['false_positive_rate'], curves['ROC']['true_positive_rate'], _ = roc_curve(\n",
    "        overall_y_test, overall_pred_test)\n",
    "    curves['PR']['precision'], curves['PR']['recall'], _ = precision_recall_curve(\n",
    "        overall_y_test, overall_pred_test_class)\n",
    "\n",
    "    # plot curves\n",
    "    plot_curves(cutoff, curves, current_params)\n",
    "\n",
    "    pr_search.append(current_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef6bc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sorted(pr_search, key=lambda d: d['test_ROC_AUC'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbd3503",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "pheno = 'test'\n",
    "run_id = 'test'\n",
    "\n",
    "os.makedirs(f\"results/{pheno}/{run_id}\", exist_ok=True)\n",
    "with open(f\"results/{pheno}/{run_id}/results.json\", \"a\") as f:\n",
    "    for i in results:\n",
    "        f.write('\\n')\n",
    "        f.write(json.dumps(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87076253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
