{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71f9cd2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import neptune\n",
    "from seaborn import heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ac9605",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340237f1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "main_path = os.path.abspath('')\n",
    "\n",
    "pheno = \"diab\"\n",
    "\n",
    "# paths\n",
    "## input paths\n",
    "\n",
    "vcf_path = f\"./data/ext_prs.90k.{pheno}.vcf\"\n",
    "ordered_target_path = f\"./data/phenotype.{pheno}.ordered\"\n",
    "ordered_covariates_path = f\"./data/cov.{pheno}.ordered\"\n",
    "\n",
    "## output paths\n",
    "target_output_path = os.path.join(main_path, \"data\", f\"target_{pheno}.csv\")\n",
    "transposed_feature_matrix_path = os.path.join(\n",
    "    main_path, \"data\", f\"feature_matrix_{pheno}.csv\")\n",
    "feature_cov_path = os.path.join(\n",
    "    main_path, \"data\", f\"feature_cov_matrix_{pheno}.csv\")\n",
    "feature_cov_hla_path = os.path.join(\n",
    "    main_path, \"data\", f\"feature_cov_hla_matrix_{pheno}.csv\")\n",
    "\n",
    "imbalance = \"SMOTE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b93d12",
   "metadata": {
    "id": "c37df085",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac23e09",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "min_delta = 0.08\n",
    "patience = 10\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788ca07f",
   "metadata": {
    "id": "efa1f81a",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbf086f",
   "metadata": {
    "id": "408810c9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ea6edb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DO_UNDERSAMPLE = True\n",
    "UNDERSAMPLE_N = 10000\n",
    "\n",
    "# training (60%), validation (20%) and testing (20%)\n",
    "df = pd.read_csv(target_output_path, header=None)\n",
    "print(\"All dfs shape\", df.shape)\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, stratify=df, random_state=5)\n",
    "train, val = train_test_split(train, test_size=0.25, stratify=train, random_state=5)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "if DO_UNDERSAMPLE:\n",
    "    train_healthy = train[train[0] == 0]\n",
    "    train_ill = train[train[0] == 1]\n",
    "    train_healthy = train_healthy.sample(UNDERSAMPLE_N)\n",
    "\n",
    "    train = pd.concat([train_ill, train_healthy])\n",
    "    print(\"New train shape\", train.shape)\n",
    "\n",
    "train_index = train.index\n",
    "val_index = val.index\n",
    "test_index = test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b26d94",
   "metadata": {
    "id": "3O5ESqvev5nv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from prs_dataset_standard import PRS_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d822a01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "de73ed98",
    "outputId": "5e5393fd-92f6-4675-9dd6-f411a2cee8f3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 4096\n",
    "imbalance_type = \"SMOTE\"\n",
    "mode = \"gen_cov_hla\"\n",
    "\n",
    "if mode == \"gen\":\n",
    "    feature_path = transposed_feature_matrix_path\n",
    "elif mode == \"cov\":\n",
    "    feature_path = ordered_covariates_path\n",
    "elif mode == \"gen_cov\":\n",
    "    feature_path = feature_cov_path\n",
    "elif mode == \"gen_cov_hla\":\n",
    "    feature_path = feature_cov_hla_path\n",
    "\n",
    "\n",
    "if imbalance_type == \"ROS\":\n",
    "    train_dataset = PRS_Dataset(feature_path, target_output_path,\n",
    "                            'train', train_index, test_index, val_index, imbalance='ROS')\n",
    "elif imbalance_type == \"SMOTE\":\n",
    "    train_dataset = PRS_Dataset(feature_path, target_output_path,\n",
    "                            'train', train_index, test_index, val_index, imbalance='SMOTE')\n",
    "else:\n",
    "    train_dataset = PRS_Dataset(feature_path, target_output_path,\n",
    "                            'train', train_index, test_index, val_index)\n",
    "    \n",
    "val_dataset = PRS_Dataset(feature_path, target_output_path,\n",
    "                          'val', train_index, test_index, val_index)\n",
    "test_dataset = PRS_Dataset(feature_path, target_output_path,\n",
    "                           'test', train_index, test_index, val_index)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "\n",
    "val_loader = DataLoader(dataset=val_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False,\n",
    "                        num_workers=2)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838f74ff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DEBUG_CASE_CONTROL_AMOUNT = True\n",
    "if DEBUG_CASE_CONTROL_AMOUNT:\n",
    "    print(imbalance_type)\n",
    "    print(\"Train\")\n",
    "    print(train_dataset.y_data.shape)\n",
    "    c = 0\n",
    "    for y in train_dataset.y_data:\n",
    "        if y[0] == 1:\n",
    "            c += 1\n",
    "    print(\"Ill\", c)\n",
    "    print(\"Val\")\n",
    "    print(val_dataset.y_data.shape)\n",
    "    c = 0\n",
    "    for y in val_dataset.y_data:\n",
    "        if y[0] == 1:\n",
    "            c += 1\n",
    "    print(\"Ill\", c)\n",
    "    print(\"Test\")\n",
    "    print(test_dataset.y_data.shape)\n",
    "    c = 0\n",
    "    for y in test_dataset.y_data:\n",
    "        if y[0] == 1:\n",
    "            c += 1\n",
    "    print(\"Ill\", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18490af5",
   "metadata": {
    "id": "e0518698",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22411e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "example = iter(test_loader)\n",
    "x_batch, y_batch = next(example)\n",
    "input_size = x_batch.shape[1]\n",
    "print(x_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e943a0",
   "metadata": {
    "id": "83af8400",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dense\n",
    "from models.model_dense import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7500fdb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# CNN\n",
    "from models.model_cnn import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383a4667",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# RNN\n",
    "from models.model_rnn import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6d0793",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# RNN CNN\n",
    "from models.model_rnn_cnn import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febd2cbe",
   "metadata": {
    "id": "32560b20",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0356ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_curves(run, curves, current_params):\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "    # PR curve\n",
    "    ax1.plot(curves['PR']['recall'], curves['PR']['precision'])\n",
    "    ax1.title.set_text('Precision-Recall Curve')\n",
    "    ax1.set_ylabel('Precision')\n",
    "    ax1.set_xlabel('Recall')\n",
    "\n",
    "    # ROC curve\n",
    "    ax2.plot(curves['ROC']['false_positive_rate'], curves['ROC']\n",
    "             ['true_positive_rate'], label='AUC = %0.2f' % current_params['test_ROC_AUC'])\n",
    "    ax2.title.set_text('ROC Curve')\n",
    "    ax2.set_ylabel('True Positive Rate')\n",
    "    ax2.set_xlabel('False Positive Rate')\n",
    "    ax2.legend(loc = 'lower right')\n",
    "\n",
    "    # confusion matrix\n",
    "    conf_matrix = np.array(([current_params['confusion_matrix']['TP'],\n",
    "                                     current_params['confusion_matrix']['FP']],\n",
    "                                   [current_params['confusion_matrix']['FN'],\n",
    "                                   current_params['confusion_matrix']['TN']]))\n",
    "    \n",
    "    \n",
    "\n",
    "    ax4 = heatmap(conf_matrix, annot=True, fmt=\".1f\")\n",
    "    ax4.set(xlabel=\"Predicted Label\", ylabel=\"True Label\")\n",
    "    ax4.title.set_text('Confusion matrix')\n",
    "\n",
    "    \n",
    "    # model info\n",
    "    text = f\"Run number: {current_params['run']}\\nTraining with the following parameters:\\n\"\n",
    "    for k, v in current_params.items():\n",
    "        text += f\"{k}: {v}\\n\"\n",
    "        \n",
    "    ax3.text(0, 0.5, text, ha='left')\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    dir_path = f\"./figures/{current_params['run_id']}\"\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.mkdir(dir_path)\n",
    "    fp = f\"{dir_path}/run{current_params['run']}_training.jpg\"\n",
    "    fig.savefig(fp, dpi=300)\n",
    "        \n",
    "    run[\"curves\"].upload(fp)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefb13d4",
   "metadata": {
    "id": "VJkdjqgP8lwR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_stats(run, loss_history, auc_history, current_params):\n",
    "    \"\"\"Plot loss and ROC AUC in jupyter notebook\"\"\"\n",
    "    for training_loss_item in loss_history['train']:\n",
    "        run[\"train/loss\"].append(training_loss_item)\n",
    "    for val_loss_item in loss_history['val']:\n",
    "        run[\"val/loss\"].append(val_loss_item)\n",
    "    \n",
    "    for training_auc_item in auc_history['train']:\n",
    "        run[\"train/auc\"].append(training_auc_item)\n",
    "    for val_auc_item in auc_history['val']:\n",
    "        run[\"val/auc\"].append(val_auc_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffef85b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def training_loop(n, epochs, run_id, learning_rate, **kwargs):\n",
    "    \"\"\"\n",
    "    Trains a single net on the supplied params.\n",
    "    Returns average ROC AUC on the whole test dataset after learning is complete.    \n",
    "    \"\"\"\n",
    "    early_stopper = EarlyStopper(patience=patience, min_delta=min_delta)\n",
    "    \n",
    "    model = Model(input_size, **kwargs).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.BCELoss()\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer,\n",
    "                                            T_0=10,  # Number of iterations for the first restart\n",
    "                                            T_mult=1,  # A factor increases TiTi after a restart\n",
    "                                            eta_min=1e-4)  # Minimum learning rate\n",
    "\n",
    "    # summary of the current model\n",
    "    current_params = {\n",
    "        'run': n,\n",
    "        'overall_epochs': epochs,\n",
    "        'lr': learning_rate,\n",
    "        \"run_id\": run_id,\n",
    "        **kwargs\n",
    "    }\n",
    "\n",
    "    auc_history = {'train': [], 'val': []}\n",
    "    aucs = {'train': [], 'val': []}\n",
    "    loss_history = {'train': [], 'val': []}\n",
    "    losses = {'train': [], 'val': []}\n",
    "    best_val_auc = 0  # ищем лучший auc по эпохам\n",
    "    best_epoch = None  # ищем лучшую эпоху\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            model.train()\n",
    "            # forward pass\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            pred = model(x_batch)\n",
    "            loss = criterion(pred, y_batch)\n",
    "            losses['train'].append(np.mean(loss.detach().cpu().numpy()))\n",
    "            aucs['train'].append(np.mean(roc_auc_score(\n",
    "                y_batch.detach().cpu().numpy(), pred.detach().cpu().numpy())))\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # check current performance on val\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x_val, y_val in val_loader:\n",
    "                x_val = x_val.to(device)\n",
    "                y_val = y_val.to(device)\n",
    "                pred_val = model(x_val)\n",
    "                loss = criterion(pred_val, y_val)\n",
    "\n",
    "                losses['val'].append(np.mean(loss.detach().cpu().numpy()))\n",
    "                aucs['val'].append(np.mean(roc_auc_score(\n",
    "                    y_val.detach().cpu().numpy(), pred_val.detach().cpu().numpy())))\n",
    "\n",
    "        # scheduler step\n",
    "        scheduler.step()\n",
    "\n",
    "        # plot statistics\n",
    "        loss_history['train'].append(sum(losses['train'])/len(losses['train']))\n",
    "        loss_history['val'].append(sum(losses['val'])/len(losses['val']))\n",
    "        validation_loss = sum(losses['val'])/len(losses['val'])\n",
    "        losses = {'train': [], 'val': []}\n",
    "\n",
    "        curr_val_auc = sum(aucs['val'])/len(aucs['val'])  # current val auc\n",
    "        auc_history['train'].append(sum(aucs['train'])/len(aucs['train']))\n",
    "        auc_history['val'].append(curr_val_auc)\n",
    "        aucs = {'train': [], 'val': []}\n",
    "\n",
    "        if curr_val_auc > best_val_auc:  # current best model\n",
    "            best_val_auc = curr_val_auc\n",
    "            best_epoch = epoch\n",
    "            best_model = model.state_dict()\n",
    "        \n",
    "        # early stopper\n",
    "        if early_stopper.early_stop(validation_loss):\n",
    "            break\n",
    "            \n",
    "    # load best model params\n",
    "    model.load_state_dict(best_model)\n",
    "    model.eval()\n",
    "    \n",
    "    overall_pred_test = []\n",
    "    overall_pred_test_class = []\n",
    "    overall_y_test = []\n",
    "    ovarall_confmatrix = np.zeros((2, 2))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_test, y_test in test_loader:\n",
    "            x_test = x_test.to(device)\n",
    "            y_test = y_test.cpu().numpy()\n",
    "            pred_test = model(x_test).detach().cpu().numpy()\n",
    "            pred_test_class = np.rint(pred_test)\n",
    "            # append predicts\n",
    "            overall_y_test += list(y_test.flatten())\n",
    "            overall_pred_test += list(pred_test.flatten())\n",
    "            overall_pred_test_class += list(pred_test_class.flatten())\n",
    "            ovarall_confmatrix += confusion_matrix(y_test, pred_test_class)\n",
    "    \n",
    "    # collect metrics\n",
    "    overall_y_test = np.array(overall_y_test).reshape(-1, 1)\n",
    "    overall_pred_test = np.array(overall_pred_test).reshape(-1, 1)\n",
    "    overall_pred_test_class = (\n",
    "        np.array(overall_pred_test_class).reshape(-1, 1))\n",
    "\n",
    "    current_params['test_ROC_AUC'] = roc_auc_score(\n",
    "        overall_y_test, overall_pred_test)\n",
    "    current_params['test_recall'] = recall_score(\n",
    "        overall_y_test, overall_pred_test_class)\n",
    "    current_params['test_precision'] = precision_score(\n",
    "        overall_y_test, overall_pred_test_class)\n",
    "    conf_matrix = {'TP': ovarall_confmatrix[0][0],\n",
    "                   'TN': ovarall_confmatrix[1][1],\n",
    "                   'FP': ovarall_confmatrix[0][1],\n",
    "                   'FN': ovarall_confmatrix[1][0]}\n",
    "    current_params['confusion_matrix'] = conf_matrix\n",
    "    \n",
    "    current_params['test_accuracy'] = accuracy_score(overall_y_test, overall_pred_test_class)\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(overall_y_test, overall_pred_test)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    current_params['test_PR_AUC'] = pr_auc\n",
    "    \n",
    "    current_params['F1-score'] = f1_score(overall_y_test, overall_pred_test_class)\n",
    "    \n",
    "    current_params['best_epochs'] = best_epoch\n",
    "    \n",
    "        \n",
    "    run = neptune.init_run(\n",
    "            project=\"NA\",       # your neptune credentials\n",
    "            api_token=\"NA\",     # your neptune credentials\n",
    "    ) \n",
    "        \n",
    "    run[\"parameters\"] = {**current_params, \"pheno\": pheno}\n",
    "    \n",
    "    # plot stats\n",
    "    plot_stats(run, loss_history, auc_history, current_params)\n",
    "    \n",
    "    # calculate curves\n",
    "    curves = {'ROC':{}, 'PR':{}}\n",
    "    curves['ROC']['false_positive_rate'], curves['ROC']['true_positive_rate'], _ = roc_curve(\n",
    "        overall_y_test, overall_pred_test)\n",
    "    curves['PR']['precision'], curves['PR']['recall'], _ = precision_recall_curve(\n",
    "        overall_y_test, overall_pred_test_class)\n",
    "    \n",
    "    # plot curves\n",
    "    plot_curves(run, curves, current_params)\n",
    "    \n",
    "    run.stop()\n",
    "    \n",
    "    return current_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02196e4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dense model info\n",
    "params = {\n",
    "    'epochs': [100],\n",
    "    'lr': [0.001],\n",
    "    'bn_momentum': [0.7, 0.9],  # batch norm momentum\n",
    "    'first_dropout': [0.7, 0.9],\n",
    "    'other_dropouts': [0.7, 0.9],\n",
    "    'lin1_output': [100, 250, 500],  # edit to change shapes of the linear layers\n",
    "    'lin2_output': [50],\n",
    "    'lin3_output': [10, 20, 40]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a36d5d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Conv model info\n",
    "params = {\n",
    "    'epochs': [200],\n",
    "    'input_dim' : [input_size],\n",
    "    'kernel_size':[2,3],\n",
    "    'stride': [2,3,4],\n",
    "    'kernel_size2':[2,3],\n",
    "    'stride2':[2,3,4],\n",
    "    'dropout' : [0.7, 0.8, 0.9],\n",
    "    'out_channels_first':[1000, 500, 250],\n",
    "    'out_channels_second':[1000, 500, 250],\n",
    "    'lr' : [0.0001],\n",
    "    'linear_first':[250, 100]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cb9c09",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# RNN model info\n",
    "params = {\n",
    "    'epochs': [200],\n",
    "    'input_dim' : [input_size],\n",
    "    'hidden_dim' : hidden_dim,\n",
    "    'dropout' : [0.7, 0.8, 0.9],\n",
    "    'bi_value' : [False, True],\n",
    "    'lr' : [0.0001]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaba8715",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# RNN CNN model info\n",
    "params = {\n",
    "    'epochs': [200],\n",
    "    'input_dim' : [input_dim],\n",
    "    'hidden_dim': hidden_dim,\n",
    "    'bi_value': [True, False],\n",
    "    'kernel_size':[2,3],\n",
    "    'stride': [2,3,4],\n",
    "    'kernel_size2':[2,3],\n",
    "    'stride2':[2,3,4],\n",
    "    'dropout' : [0.7, 0.8, 0.9],\n",
    "    'out_channels_first':[1000, 500, 250],\n",
    "    'out_channels_second':[1000, 500, 250],\n",
    "    'lr' : [0.0001],\n",
    "    'linear_first':[250, 100]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff728a0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "run_id = int(time.time())\n",
    "print(\"Run id is\", run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a19e9ba",
   "metadata": {
    "id": "4AV-znHOJVDS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# hyperparam grid search\n",
    "grid_search = []\n",
    "total_searches = np.prod(np.array([len(v) for v in params.values()]))\n",
    "i = 1\n",
    "\n",
    "for params_combination in list(itertools.product(*params.values())):\n",
    "    params_dict = dict(zip(params.keys(), list(params_combination)))\n",
    "    \n",
    "    epochs_number = params_dict[\"epochs\"]\n",
    "    params_dict.pop(\"epochs\")\n",
    "    \n",
    "    learning_rate = params_dict[\"lr\"]\n",
    "    params_dict.pop(\"lr\")\n",
    "    \n",
    "    print(f\"Grid Serach step {i} of total {total_searches}\")\n",
    "    try:\n",
    "        grid_search.append(training_loop(i, epochs_number, run_id, learning_rate, **params_dict))\n",
    "    except Exception as e:\n",
    "        print(f\"!!! Error: {e}\")\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1253bd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results = sorted(grid_search, key=lambda d: d['test_ROC_AUC'], reverse=True)\n",
    "\n",
    "import json\n",
    "\n",
    "os.makedirs(f\"results/{pheno}/{run_id}\", exist_ok=True)\n",
    "with open(f\"results/{pheno}/{run_id}/results.json\", \"w\") as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265da43d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results[0] # best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241779f5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i, g in enumerate(grid_search):\n",
    "    if g == results[0]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bff531",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Linear model \n",
    "- Run a single run or grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb53e23",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386815fc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter = 1000, penalty = 'l2', solver='saga')\n",
    "logreg.fit(train_dataset.x_data.numpy(), train_dataset.y_data.numpy().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c949f81b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "overall_y_test = test_dataset.y_data.numpy().ravel()\n",
    "overall_pred_test = logreg.predict_proba(test_dataset.x_data.numpy())[:, 1]\n",
    "overall_pred_test_class = np.rint(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e67d89",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "current_params = {}\n",
    "ovarall_confmatrix = np.zeros((2, 2))\n",
    "\n",
    "current_params['test_ROC_AUC'] = roc_auc_score(\n",
    "        overall_y_test, overall_pred_test)\n",
    "current_params['test_recall'] = recall_score(\n",
    "    overall_y_test, overall_pred_test_class)\n",
    "current_params['test_precision'] = precision_score(\n",
    "    overall_y_test, overall_pred_test_class)\n",
    "ovarall_confmatrix = confusion_matrix(overall_y_test, overall_pred_test_class)\n",
    "conf_matrix = {'TP': ovarall_confmatrix[0][0],\n",
    "               'TN': ovarall_confmatrix[1][1],\n",
    "               'FP': ovarall_confmatrix[0][1],\n",
    "               'FN': ovarall_confmatrix[1][0]}\n",
    "current_params['confusion_matrix'] = conf_matrix\n",
    "\n",
    "current_params['test_accuracy'] = accuracy_score(overall_y_test, overall_pred_test_class)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(overall_y_test, overall_pred_test)\n",
    "pr_auc = auc(recall, precision)\n",
    "current_params['test_PR_AUC'] = pr_auc\n",
    "current_params['F1-score'] = f1_score(overall_y_test, overall_pred_test_class)\n",
    "\n",
    "current_params[\"run\"] = -1\n",
    "current_params[\"run_id\"] = run_id\n",
    "\n",
    "run = neptune.init_run(\n",
    "        project=\"NA\",       # your neptune credentials\n",
    "        api_token=\"NA\",     # your neptune credentials\n",
    ") \n",
    "        \n",
    "run[\"parameters\"] = {**current_params, \"pheno\": pheno}\n",
    "\n",
    "curves = {'ROC':{}, 'PR':{}}\n",
    "curves['ROC']['false_positive_rate'], curves['ROC']['true_positive_rate'], _ = roc_curve(\n",
    "    overall_y_test, overall_pred_test)\n",
    "curves['PR']['precision'], curves['PR']['recall'], _ = precision_recall_curve(\n",
    "    overall_y_test, overall_pred_test_class)\n",
    "\n",
    "# plot curves\n",
    "plot_curves(run, curves, current_params)\n",
    "\n",
    "run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20098759",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "current_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
