{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19062b7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "from seaborn import heatmap\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    auc,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225bd4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prs_dataset_standard import PRS_Dataset\n",
    "import compare_auc_delong_xu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b5f2c5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c819473",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "main_path = os.path.abspath(\"\")\n",
    "\n",
    "pheno = \"bmi\"\n",
    "\n",
    "# paths\n",
    "## input paths\n",
    "vcf_path = f\"./data/ext_prs.90k.{pheno}.vcf\"\n",
    "ordered_target_path = f\"./data/phenotype.{pheno}.ordered\"\n",
    "ordered_covariates_path = f\"./data/cov.{pheno}.ordered\"\n",
    "\n",
    "## output paths\n",
    "target_output_path = os.path.join(main_path, \"data\", f\"target_{pheno}.csv\")\n",
    "transposed_feature_matrix_path = os.path.join(\n",
    "    main_path, \"data\", f\"feature_matrix_{pheno}.csv\"\n",
    ")\n",
    "feature_cov_path = os.path.join(main_path, \"data\", f\"feature_cov_matrix_{pheno}.csv\")\n",
    "feature_cov_hla_path = os.path.join(\n",
    "    main_path, \"data\", f\"feature_cov_hla_matrix_{pheno}.csv\"\n",
    ")\n",
    "\n",
    "# json with results\n",
    "json_output_raw = os.path.join(main_path, f\"delong_cycle_cv_raw_{pheno}.json\")\n",
    "json_output_summary = os.path.join(main_path, f\"delong_cycle_cv_summary_{pheno}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080e91da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping settings\n",
    "min_delta = 0.08\n",
    "patience = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80fdde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26a8323",
   "metadata": {},
   "source": [
    "## Data and dataset settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09d52fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many CV cycles\n",
    "num_of_cycles = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec4ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data settings\n",
    "DO_UNDERSAMPLE = True\n",
    "UNDERSAMPLE_N = 10000\n",
    "\n",
    "batch_size = 4096\n",
    "imbalance_type = \"SMOTE\"\n",
    "mode = \"gen_cov\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7912e439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(current_results, file_name=f\"./delong_cycle_cv_raw.json\"):\n",
    "    with open(file_name, \"a\") as file:\n",
    "        file.write(\"\\n\")\n",
    "        file.write(json.dumps(current_results, indent=1, cls=NpEncoder))\n",
    "\n",
    "\n",
    "def write_json_2dicts(dict1, dict2, file_name=f\"./delong_cycle_cv_summary.json\"):\n",
    "    output = []\n",
    "    output.append(dict1)\n",
    "    output.append(dict2)\n",
    "\n",
    "    with open(file_name, \"a\") as file:\n",
    "        file.write(\"\\n\")\n",
    "        file.write(json.dumps(output, indent=1, cls=NpEncoder))\n",
    "\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8205c1f2",
   "metadata": {
    "id": "e0518698",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fe2233",
   "metadata": {
    "id": "83af8400",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dense\n",
    "from model_dense import Model as dense_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c181aac6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# CNN\n",
    "from model_cnn import Model as cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfda1a9c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# RNN\n",
    "from model_rnn import Model as rnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb35b36",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# RNN CNN\n",
    "from model_rnn_cnn import Model as rnn_cnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238504d4",
   "metadata": {
    "id": "32560b20",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5d08ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38797c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_curves(curves, current_params):\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "    # PR curve\n",
    "    ax1.plot(curves[\"PR\"][\"recall\"], curves[\"PR\"][\"precision\"])\n",
    "    ax1.title.set_text(\"Precision-Recall Curve\")\n",
    "    ax1.set_ylabel(\"Precision\")\n",
    "    ax1.set_xlabel(\"Recall\")\n",
    "\n",
    "    # ROC curve\n",
    "    ax2.plot(\n",
    "        curves[\"ROC\"][\"false_positive_rate\"],\n",
    "        curves[\"ROC\"][\"true_positive_rate\"],\n",
    "        label=\"AUC = %0.2f\" % current_params[\"test_ROC_AUC\"],\n",
    "    )\n",
    "    ax2.title.set_text(\"ROC Curve\")\n",
    "    ax2.set_ylabel(\"True Positive Rate\")\n",
    "    ax2.set_xlabel(\"False Positive Rate\")\n",
    "    ax2.legend(loc=\"lower right\")\n",
    "\n",
    "    # confusion matrix\n",
    "    conf_matrix = np.array(\n",
    "        (\n",
    "            [\n",
    "                current_params[\"confusion_matrix\"][\"TP\"],\n",
    "                current_params[\"confusion_matrix\"][\"FP\"],\n",
    "            ],\n",
    "            [\n",
    "                current_params[\"confusion_matrix\"][\"FN\"],\n",
    "                current_params[\"confusion_matrix\"][\"TN\"],\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    ax4 = heatmap(conf_matrix, annot=True, fmt=\".1f\")\n",
    "    ax4.set(xlabel=\"Predicted Label\", ylabel=\"True Label\")\n",
    "    ax4.title.set_text(\"Confusion matrix\")\n",
    "\n",
    "    # model info\n",
    "    text = \"Training with the following parameters:\\n\"\n",
    "    for k, v in current_params.items():\n",
    "        text += f\"{k}: {v}\\n\"\n",
    "\n",
    "    ax3.text(0, 0.5, text, ha=\"left\")\n",
    "    ax3.axis(\"off\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c31e6b",
   "metadata": {
    "id": "VJkdjqgP8lwR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_stats(loss_history, auc_history):\n",
    "    \"\"\"Plot loss and ROC AUC in jupyter notebook\"\"\"\n",
    "\n",
    "    fig, (ax1, ax2) = pl.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # loss\n",
    "    training_loss = loss_history[\"train\"]\n",
    "    val_loss = loss_history[\"val\"]\n",
    "\n",
    "    epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "    ax1.plot(epoch_count, training_loss, \"-r\")\n",
    "    ax1.plot(epoch_count, val_loss, \"-b\")\n",
    "    ax1.legend([\"Training loss\", \"Val loss\"])\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "\n",
    "    # auc\n",
    "    training_auc = auc_history[\"train\"]\n",
    "    val_auc = auc_history[\"val\"]\n",
    "\n",
    "    ax2.plot(epoch_count, training_auc, \"-r\")\n",
    "    ax2.plot(epoch_count, val_auc, \"-b\")\n",
    "    ax2.legend([\"Training ROC AUC\", \"Val ROC AUC\"])\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"ROC AUC\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(pl.gcf())\n",
    "    # time.sleep(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f515b7a9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def training_loop(n, model, epochs, run_id, learning_rate, **kwargs):\n",
    "    \"\"\"\n",
    "    Trains a single net on the supplied params.\n",
    "    Returns average ROC AUC on the whole test dataset after learning is complete.\n",
    "    \"\"\"\n",
    "    early_stopper = EarlyStopper(patience=patience, min_delta=min_delta)\n",
    "\n",
    "    model = model(input_size, **kwargs).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.BCELoss()\n",
    "    scheduler = CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        T_0=10,  # Number of iterations for the first restart\n",
    "        T_mult=1,  # A factor increases TiTi after a restart\n",
    "        eta_min=1e-4,  # Minimum learning rate\n",
    "    )\n",
    "    # summary of the current model\n",
    "    current_params_temp = {\n",
    "        \"run\": n,\n",
    "        \"overall_epochs\": epochs,\n",
    "        \"lr\": learning_rate,\n",
    "        \"run_id\": run_id,\n",
    "        **kwargs,\n",
    "    }\n",
    "\n",
    "    auc_history = {\"train\": [], \"val\": []}\n",
    "    aucs = {\"train\": [], \"val\": []}\n",
    "    loss_history = {\"train\": [], \"val\": []}\n",
    "    losses = {\"train\": [], \"val\": []}\n",
    "    best_val_auc = 0   \n",
    "    best_epoch = None   \n",
    "    best_model = None\n",
    "\n",
    "    print(\"Amount of epochs\")\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            model.train()\n",
    "            # forward pass\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            pred = model(x_batch)\n",
    "            loss = criterion(pred, y_batch)\n",
    "            losses[\"train\"].append(np.mean(loss.detach().cpu().numpy()))\n",
    "            aucs[\"train\"].append(\n",
    "                np.mean(\n",
    "                    roc_auc_score(\n",
    "                        y_batch.detach().cpu().numpy(), pred.detach().cpu().numpy()\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # check current performance on val\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x_val, y_val in val_loader:\n",
    "                x_val = x_val.to(device)\n",
    "                y_val = y_val.to(device)\n",
    "                pred_val = model(x_val)\n",
    "                loss = criterion(pred_val, y_val)\n",
    "\n",
    "                losses[\"val\"].append(np.mean(loss.detach().cpu().numpy()))\n",
    "                aucs[\"val\"].append(\n",
    "                    np.mean(\n",
    "                        roc_auc_score(\n",
    "                            y_val.detach().cpu().numpy(),\n",
    "                            pred_val.detach().cpu().numpy(),\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        # scheduler step\n",
    "        scheduler.step()\n",
    "\n",
    "        # plot statistics\n",
    "        loss_history[\"train\"].append(sum(losses[\"train\"]) / len(losses[\"train\"]))\n",
    "        loss_history[\"val\"].append(sum(losses[\"val\"]) / len(losses[\"val\"]))\n",
    "        validation_loss = sum(losses[\"val\"]) / len(losses[\"val\"])\n",
    "        losses = {\"train\": [], \"val\": []}\n",
    "\n",
    "        curr_val_auc = sum(aucs[\"val\"]) / len(aucs[\"val\"])  # current val auc\n",
    "        auc_history[\"train\"].append(sum(aucs[\"train\"]) / len(aucs[\"train\"]))\n",
    "        auc_history[\"val\"].append(curr_val_auc)\n",
    "        aucs = {\"train\": [], \"val\": []}\n",
    "\n",
    "        if curr_val_auc > best_val_auc:  # current best model\n",
    "            best_val_auc = curr_val_auc\n",
    "            best_epoch = epoch\n",
    "            best_model = model.state_dict()\n",
    "\n",
    "        # early stopper\n",
    "        if early_stopper.early_stop(validation_loss):\n",
    "            break\n",
    "\n",
    "        # plot stats\n",
    "        if epoch % 10 == 0:\n",
    "            plot_stats(loss_history, auc_history)\n",
    "\n",
    "    ################################################\n",
    "    # load best model params\n",
    "    model.load_state_dict(best_model)\n",
    "    model.eval()\n",
    "\n",
    "    overall_pred_test = []\n",
    "    overall_pred_test_class = []\n",
    "    overall_y_test = []\n",
    "    ovarall_confmatrix = np.zeros((2, 2))\n",
    "    # current_params_temp = final_current_params.copy()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_test, y_test in test_loader:\n",
    "            x_test = x_test.to(device)\n",
    "            y_test = y_test.cpu().numpy()\n",
    "            pred_test = model(x_test).detach().cpu().numpy()\n",
    "\n",
    "            pred_test_class = np.rint(pred_test)\n",
    "\n",
    "            # append predicts\n",
    "            overall_y_test += list(y_test.flatten())\n",
    "            overall_pred_test += list(pred_test.flatten())\n",
    "            overall_pred_test_class += list(pred_test_class.flatten())\n",
    "            ovarall_confmatrix += confusion_matrix(y_test, pred_test_class)\n",
    "\n",
    "    # collect metrics\n",
    "    overall_y_test = np.array(overall_y_test).reshape(-1, 1)\n",
    "    overall_pred_test = np.array(overall_pred_test).reshape(-1, 1)\n",
    "    overall_pred_test_class = np.array(overall_pred_test_class).reshape(-1, 1)\n",
    "\n",
    "    current_params_temp[\"test_ROC_AUC\"] = roc_auc_score(\n",
    "        overall_y_test, overall_pred_test\n",
    "    )\n",
    "\n",
    "    current_params_temp[\"auc_delong\"], current_params_temp[\"variances_delong\"] = (\n",
    "        compare_auc_delong_xu.delong_roc_variance(overall_y_test, overall_pred_test)\n",
    "    )\n",
    "\n",
    "    current_params_temp[\"test_recall\"] = recall_score(\n",
    "        overall_y_test, overall_pred_test_class\n",
    "    )\n",
    "    current_params_temp[\"test_precision\"] = precision_score(\n",
    "        overall_y_test, overall_pred_test_class\n",
    "    )\n",
    "    conf_matrix = {\n",
    "        \"TP\": ovarall_confmatrix[0][0],\n",
    "        \"TN\": ovarall_confmatrix[1][1],\n",
    "        \"FP\": ovarall_confmatrix[0][1],\n",
    "        \"FN\": ovarall_confmatrix[1][0],\n",
    "    }\n",
    "    current_params_temp[\"confusion_matrix\"] = conf_matrix\n",
    "\n",
    "    current_params_temp[\"test_accuracy\"] = accuracy_score(\n",
    "        overall_y_test, overall_pred_test_class\n",
    "    )\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(\n",
    "        overall_y_test, overall_pred_test\n",
    "    )\n",
    "    pr_auc = auc(recall, precision)\n",
    "    current_params_temp[\"test_PR_AUC\"] = pr_auc\n",
    "\n",
    "    current_params_temp[\"F1-score\"] = f1_score(overall_y_test, overall_pred_test_class)\n",
    "\n",
    "    # calculate curves\n",
    "    curves = {\"ROC\": {}, \"PR\": {}}\n",
    "    curves[\"ROC\"][\"false_positive_rate\"], curves[\"ROC\"][\"true_positive_rate\"], _ = (\n",
    "        roc_curve(overall_y_test, overall_pred_test)\n",
    "    )\n",
    "    curves[\"PR\"][\"precision\"], curves[\"PR\"][\"recall\"], _ = precision_recall_curve(\n",
    "        overall_y_test, overall_pred_test_class\n",
    "    )\n",
    "\n",
    "    # plot curves\n",
    "    plot_curves(curves, current_params_temp)\n",
    "\n",
    "    return current_params_temp, overall_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3af7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_nn_params(pheno):\n",
    "    if pheno == \"bmi\":\n",
    "        dense_params = {\n",
    "            \"model\": dense_model,\n",
    "            \"model_name\": \"mlp\",\n",
    "            \"epochs\": 200,\n",
    "            \"lr\": 0.001,\n",
    "            \"bn_momentum\": [0.9],\n",
    "            \"first_dropout\": [0.9],\n",
    "            \"other_dropouts\": [0.9],\n",
    "            \"lin1_output\": [300],\n",
    "            \"lin2_output\": [100, 150],\n",
    "            \"lin3_output\": [10, 25, 35],\n",
    "        }\n",
    "        ## cnn\n",
    "        cnn_params = {\n",
    "            \"model\": cnn_model,\n",
    "            \"model_name\": \"cnn\",\n",
    "            \"epochs\": 150,\n",
    "            \"lr\": 0.001,\n",
    "            \"out_channels_first\": [500, 250],\n",
    "            \"out_channels_second\": [150],\n",
    "            \"linear_first\": [100, 50],\n",
    "            \"kernel_size\": [1],\n",
    "            \"stride\": [1, 2],\n",
    "            \"drop1\": [0.9],\n",
    "        }\n",
    "\n",
    "        rnn_params = {\n",
    "            \"model\": rnn_model,\n",
    "            \"model_name\": \"rnn\",\n",
    "            \"epochs\": 150,\n",
    "            \"lr\": 0.001,\n",
    "            \"hidden_dim\": [300, 200, 100, 50],\n",
    "            \"target_size\": [1],\n",
    "        }\n",
    "\n",
    "        rnn_cnn_params = {\n",
    "            \"model\": rnn_cnn_model,\n",
    "            \"model_name\": \"rnn_cnn\",\n",
    "            \"epochs\": 150,\n",
    "            \"lr\": 0.001,\n",
    "            \"bn_momentum\": [0.8],\n",
    "            \"drop\": [0.9],\n",
    "            \"hidden1\": [500],\n",
    "            \"conv1\": [1000],\n",
    "            \"conv2\": [2000, 1000],\n",
    "            \"lin1\": [500, 250],\n",
    "        }\n",
    "\n",
    "    elif pheno == \"diab\":\n",
    "        dense_params = {\n",
    "            \"model\": dense_model,\n",
    "            \"model_name\": \"mlp\",\n",
    "            \"epochs\": 200,\n",
    "            \"lr\": 0.001,\n",
    "            \"bn_momentum\": [0.9],\n",
    "            \"first_dropout\": [0.9],\n",
    "            \"other_dropouts\": [0.9],\n",
    "            \"lin1_output\": [100],\n",
    "            \"lin2_output\": [50, 75],\n",
    "            \"lin3_output\": [\n",
    "                10,\n",
    "                20,\n",
    "                40,\n",
    "            ],\n",
    "        }\n",
    "\n",
    "        cnn_params = {\n",
    "            \"model\": cnn_model,\n",
    "            \"model_name\": \"cnn\",\n",
    "            \"epochs\": 150,\n",
    "            \"lr\": 0.01,\n",
    "            \"out_channels_first\": [500],\n",
    "            \"out_channels_second\": [150],\n",
    "            \"linear_first\": [100],\n",
    "            \"kernel_size\": [1],\n",
    "            \"stride\": [1, 2],\n",
    "            \"drop1\": [0.9, 0.8],\n",
    "        }\n",
    "\n",
    "        rnn_params = {\n",
    "            \"model\": rnn_model,\n",
    "            \"model_name\": \"rnn\",\n",
    "            \"epochs\": 150,\n",
    "            \"lr\": 0.001,\n",
    "            \"hidden_dim\": [300, 200, 100, 50],\n",
    "            \"target_size\": [1],\n",
    "        }\n",
    "\n",
    "        rnn_cnn_params = {\n",
    "            \"model\": rnn_cnn_model,\n",
    "            \"model_name\": \"rnn_cnn\",\n",
    "            \"epochs\": 150,\n",
    "            \"lr\": 0.001,\n",
    "            \"bn_momentum\": [0.8],\n",
    "            \"drop\": [0.9],\n",
    "            \"hidden1\": [500],\n",
    "            \"conv1\": [1000],\n",
    "            \"conv2\": [2000, 1000],\n",
    "            \"lin1\": [500, 250],\n",
    "        }\n",
    "\n",
    "    elif pheno == \"psor\":\n",
    "        dense_params = {\n",
    "            \"model\": dense_model,\n",
    "            \"model_name\": \"mlp\",\n",
    "            \"epochs\": 200,\n",
    "            \"lr\": 0.001,\n",
    "            \"bn_momentum\": [0.9],\n",
    "            \"first_dropout\": [0.9],\n",
    "            \"other_dropouts\": [0.9],\n",
    "            \"lin1_output\": [100],\n",
    "            \"lin2_output\": [50, 75],\n",
    "            \"lin3_output\": [\n",
    "                10,\n",
    "                20,\n",
    "                40,\n",
    "            ],\n",
    "        }\n",
    "\n",
    "        cnn_params = {\n",
    "            \"model\": cnn_model,\n",
    "            \"model_name\": \"cnn\",\n",
    "            \"epochs\": 150,\n",
    "            \"lr\": 0.001,\n",
    "            \"out_channels_first\": [500, 250],\n",
    "            \"out_channels_second\": [150],\n",
    "            \"linear_first\": [100, 50],\n",
    "            \"kernel_size\": [1],\n",
    "            \"stride\": [1, 2],\n",
    "            \"drop1\": [0.9],\n",
    "        }\n",
    "\n",
    "        rnn_params = {\n",
    "            \"model\": rnn_model,\n",
    "            \"model_name\": \"rnn\",\n",
    "            \"epochs\": 150,\n",
    "            \"lr\": 0.001,\n",
    "            \"hidden_dim\": [300, 200, 100, 50],\n",
    "            \"target_size\": [1],\n",
    "        }\n",
    "\n",
    "        rnn_cnn_params = {\n",
    "            \"model\": rnn_cnn_model,\n",
    "            \"model_name\": \"rnn_cnn\",\n",
    "            \"epochs\": 150,\n",
    "            \"lr\": 0.001,\n",
    "            \"bn_momentum\": [0.8],\n",
    "            \"drop\": [0.9, 0.8],\n",
    "            \"hidden1\": [500],\n",
    "            \"conv1\": [1000],\n",
    "            \"conv2\": [2000, 1000],\n",
    "            \"lin1\": [500, 250],\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Incorrect phenotype\")\n",
    "\n",
    "    return [dense_params, cnn_params, rnn_params, rnn_cnn_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdd37e2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "run_id = int(time.time())\n",
    "print(\"Run id is\", run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b65de00",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129a5620",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def lasso_train(train_dataset):\n",
    "    logreg = LogisticRegression(max_iter=1000, penalty=\"l2\", solver=\"saga\")\n",
    "    logreg.fit(train_dataset.x_data.numpy(), train_dataset.y_data.numpy().ravel())\n",
    "\n",
    "    overall_y_test = test_dataset.y_data.numpy().ravel()\n",
    "    overall_pred_test = logreg.predict_proba(test_dataset.x_data.numpy())[:, 1]\n",
    "\n",
    "    overall_pred_test_class = np.rint(overall_pred_test)\n",
    "\n",
    "    current_params = {}\n",
    "    ovarall_confmatrix = np.zeros((2, 2))\n",
    "\n",
    "    current_params[\"test_ROC_AUC\"] = roc_auc_score(overall_y_test, overall_pred_test)\n",
    "\n",
    "    current_params[\"auc_delong\"], current_params[\"variances_delong\"] = (\n",
    "        compare_auc_delong_xu.delong_roc_variance(overall_y_test, overall_pred_test)\n",
    "    )\n",
    "\n",
    "    current_params[\"test_recall\"] = recall_score(\n",
    "        overall_y_test, overall_pred_test_class\n",
    "    )\n",
    "    current_params[\"test_precision\"] = precision_score(\n",
    "        overall_y_test, overall_pred_test_class\n",
    "    )\n",
    "    ovarall_confmatrix = confusion_matrix(overall_y_test, overall_pred_test_class)\n",
    "    conf_matrix = {\n",
    "        \"TP\": ovarall_confmatrix[0][0],\n",
    "        \"TN\": ovarall_confmatrix[1][1],\n",
    "        \"FP\": ovarall_confmatrix[0][1],\n",
    "        \"FN\": ovarall_confmatrix[1][0],\n",
    "    }\n",
    "    current_params[\"confusion_matrix\"] = conf_matrix\n",
    "\n",
    "    current_params[\"test_accuracy\"] = accuracy_score(\n",
    "        overall_y_test, overall_pred_test_class\n",
    "    )\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(\n",
    "        overall_y_test, overall_pred_test\n",
    "    )\n",
    "    pr_auc = auc(recall, precision)\n",
    "    current_params[\"test_PR_AUC\"] = pr_auc\n",
    "    current_params[\"F1-score\"] = f1_score(overall_y_test, overall_pred_test_class)\n",
    "\n",
    "    curves = {\"ROC\": {}, \"PR\": {}}\n",
    "    curves[\"ROC\"][\"false_positive_rate\"], curves[\"ROC\"][\"true_positive_rate\"], _ = (\n",
    "        roc_curve(overall_y_test, overall_pred_test)\n",
    "    )\n",
    "    curves[\"PR\"][\"precision\"], curves[\"PR\"][\"recall\"], _ = precision_recall_curve(\n",
    "        overall_y_test, overall_pred_test_class\n",
    "    )\n",
    "\n",
    "    # plot curves\n",
    "    plot_curves(curves, current_params)\n",
    "\n",
    "    return current_params, overall_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51b3785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch(i, model, run_id, learning_rate, params_dict):\n",
    "\n",
    "    gs_results = []\n",
    "    epochs = params_dict.pop(\"epochs\")\n",
    "\n",
    "    print(\n",
    "        f\"GS will run {np.prod(np.array([len(v) for v in params_dict.values()]))} cycles\"\n",
    "    )\n",
    "\n",
    "    for params_combination in list(itertools.product(*params.values())):\n",
    "        params_dict = dict(zip(params.keys(), list(params_combination)))\n",
    "\n",
    "        print(f\"params_dict: {params_dict}\")\n",
    "\n",
    "        perfomances, preds = training_loop(\n",
    "            i, model, epochs, run_id, learning_rate, **params_dict\n",
    "        )\n",
    "\n",
    "        perfomances[\"predictions\"] = preds\n",
    "\n",
    "        gs_results.append(perfomances)\n",
    "\n",
    "    results = sorted(gs_results, key=lambda d: d[\"test_ROC_AUC\"], reverse=True)\n",
    "\n",
    "    best_pred = results[0].pop(\"predictions\")\n",
    "\n",
    "    return results[0], best_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a833577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metircs_average_prep(cv_average_metics, current_metrics):\n",
    "\n",
    "    model_list = [\n",
    "        \"lasso\",\n",
    "        \"mlp\",\n",
    "        \"cnn\",\n",
    "        \"rnn\",\n",
    "        \"rnn_cnn\",\n",
    "    ]\n",
    "    metric_list = [\n",
    "        \"test_ROC_AUC\",\n",
    "        \"test_recall\",\n",
    "        \"test_precision\",\n",
    "        \"test_accuracy\",\n",
    "        \"test_PR_AUC\",\n",
    "        \"F1-score\",\n",
    "    ]\n",
    "\n",
    "    for model in model_list:\n",
    "        for metric in metric_list:\n",
    "            if metric in cv_average_metics[model]:\n",
    "                cv_average_metics[model][metric].append(current_metrics[model][metric])\n",
    "            else:\n",
    "                cv_average_metics[model][metric] = []\n",
    "\n",
    "\n",
    "def metircs_average(cv_average_metics):\n",
    "\n",
    "    average_metrics = {}\n",
    "\n",
    "    model_list = [\n",
    "        \"lasso\",\n",
    "        \"mlp\",\n",
    "        \"cnn\",\n",
    "        \"rnn\",\n",
    "        \"rnn_cnn\",\n",
    "    ]\n",
    "    metric_list = [\n",
    "        \"test_ROC_AUC\",\n",
    "        \"test_recall\",\n",
    "        \"test_precision\",\n",
    "        \"test_accuracy\",\n",
    "        \"test_PR_AUC\",\n",
    "        \"F1-score\",\n",
    "    ]\n",
    "\n",
    "    for model in model_list:\n",
    "        average_metrics[model] = []\n",
    "\n",
    "        for metric in metric_list:\n",
    "            data = np.array(cv_average_metics[model][metric])\n",
    "            m = f\"{metric} = {round(np.mean(data), 3)} +- {round(np.std(data, ddof=1) / np.sqrt(np.size(data)), 3)}\"\n",
    "            average_metrics[model].append(m)\n",
    "\n",
    "    return average_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3d58b2",
   "metadata": {},
   "source": [
    "# 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811f8b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_p_value_results = {}\n",
    "cv_average_metics = {}\n",
    "\n",
    "cv_current_metics = {\n",
    "    \"lasso\": {},\n",
    "    \"mlp\": {},\n",
    "    \"cnn\": {},\n",
    "    \"rnn\": {},\n",
    "    \"rnn_cnn\": {},\n",
    "}\n",
    "\n",
    "\n",
    "for i in range(num_of_cycles):\n",
    "    print(f\"Run {i}/{num_of_cycles}\")\n",
    "\n",
    "    df = pd.read_csv(target_output_path, header=None)\n",
    "    print(\"All dfs shape\", df.shape)\n",
    "\n",
    "    train_classic, test = train_test_split(\n",
    "        df, test_size=0.2, stratify=df, random_state=i\n",
    "    )\n",
    "    train, val = train_test_split(\n",
    "        train_classic, test_size=0.25, stratify=train_classic, random_state=i\n",
    "    )  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "    ######################## dataset prep ########################\n",
    "    ### for neural nets ###\n",
    "    if DO_UNDERSAMPLE:\n",
    "        train_healthy = train[train[0] == 0]\n",
    "        train_ill = train[train[0] == 1]\n",
    "        train_healthy = train_healthy.sample(UNDERSAMPLE_N)\n",
    "\n",
    "        train = pd.concat([train_ill, train_healthy])\n",
    "        print(\"New train shape\", train.shape)\n",
    "\n",
    "    ### for classic models ###\n",
    "    if DO_UNDERSAMPLE:\n",
    "        train_healthy_classic = train_classic[train_classic[0] == 0]\n",
    "        train_ill_classic = train_classic[train_classic[0] == 1]\n",
    "        train_healthy_classic = train_healthy_classic.sample(UNDERSAMPLE_N)\n",
    "\n",
    "        train_classic = pd.concat([train_ill_classic, train_healthy_classic])\n",
    "        print(\"New train shape\", train.shape)\n",
    "\n",
    "    train_index = train.index\n",
    "    train_index_classic = train_classic.index\n",
    "    val_index = val.index\n",
    "    test_index = test.index\n",
    "\n",
    "    # Dataset prep\n",
    "    if mode == \"gen\":\n",
    "        feature_path = transposed_feature_matrix_path\n",
    "    elif mode == \"cov\":\n",
    "        feature_path = ordered_covariates_path\n",
    "    elif mode == \"gen_cov\":\n",
    "        feature_path = feature_cov_path\n",
    "    elif mode == \"gen_cov_hla\":\n",
    "        feature_path = feature_cov_hla_path\n",
    "\n",
    "    #### for neural nets ####\n",
    "    if imbalance_type == \"ROS\":\n",
    "        train_dataset = PRS_Dataset(\n",
    "            feature_path,\n",
    "            target_output_path,\n",
    "            \"train\",\n",
    "            train_index,\n",
    "            test_index,\n",
    "            val_index,\n",
    "            imbalance=\"ROS\",\n",
    "        )\n",
    "    elif imbalance_type == \"SMOTE\":\n",
    "        train_dataset = PRS_Dataset(\n",
    "            feature_path,\n",
    "            target_output_path,\n",
    "            \"train\",\n",
    "            train_index,\n",
    "            test_index,\n",
    "            val_index,\n",
    "            imbalance=\"SMOTE\",\n",
    "        )\n",
    "    else:\n",
    "        train_dataset = PRS_Dataset(\n",
    "            feature_path,\n",
    "            target_output_path,\n",
    "            \"train\",\n",
    "            train_index,\n",
    "            test_index,\n",
    "            val_index,\n",
    "        )\n",
    "\n",
    "    val_dataset = PRS_Dataset(\n",
    "        feature_path, target_output_path, \"val\", train_index, test_index, val_index\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=2\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        dataset=val_dataset, batch_size=batch_size, shuffle=False, num_workers=2\n",
    "    )\n",
    "\n",
    "    #### for classic models ####\n",
    "    if imbalance_type == \"ROS\":\n",
    "        train_dataset_classic = PRS_Dataset(\n",
    "            feature_path,\n",
    "            target_output_path,\n",
    "            \"train\",\n",
    "            train_index_classic,\n",
    "            test_index,\n",
    "            val_index,\n",
    "            imbalance=\"ROS\",\n",
    "        )\n",
    "    elif imbalance_type == \"SMOTE\":\n",
    "        train_dataset_classic = PRS_Dataset(\n",
    "            feature_path,\n",
    "            target_output_path,\n",
    "            \"train\",\n",
    "            train_index_classic,\n",
    "            test_index,\n",
    "            val_index,\n",
    "            imbalance=\"SMOTE\",\n",
    "        )\n",
    "    else:\n",
    "        train_dataset_classic = PRS_Dataset(\n",
    "            feature_path,\n",
    "            target_output_path,\n",
    "            \"train\",\n",
    "            train_index_classic,\n",
    "            test_index,\n",
    "            val_index,\n",
    "        )\n",
    "\n",
    "    test_dataset = PRS_Dataset(\n",
    "        feature_path, target_output_path, \"test\", train_index, test_index, val_index\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=2\n",
    "    )\n",
    "\n",
    "    # tests\n",
    "    DEBUG_CASE_CONTROL_AMOUNT = True\n",
    "    if DEBUG_CASE_CONTROL_AMOUNT:\n",
    "        print(imbalance_type)\n",
    "        print(\"Train\")\n",
    "        print(train_dataset.y_data.shape)\n",
    "        c = 0\n",
    "        for y in train_dataset.y_data:\n",
    "            if y[0] == 1:\n",
    "                c += 1\n",
    "        print(\"Ill\", c)\n",
    "        print(\"Val\")\n",
    "        print(val_dataset.y_data.shape)\n",
    "        c = 0\n",
    "        for y in val_dataset.y_data:\n",
    "            if y[0] == 1:\n",
    "                c += 1\n",
    "        print(\"Ill\", c)\n",
    "        print(\"Test\")\n",
    "        print(test_dataset.y_data.shape)\n",
    "        c = 0\n",
    "        for y in test_dataset.y_data:\n",
    "            if y[0] == 1:\n",
    "                c += 1\n",
    "        print(\"Ill\", c)\n",
    "\n",
    "    example = iter(train_loader)\n",
    "    x_batch, y_batch = next(example)\n",
    "    input_size = x_batch.shape[1]\n",
    "    print(f\"input size is {x_batch.shape[1]}\")\n",
    "\n",
    "    ######################## train and test ########################\n",
    "    # Neural nets\n",
    "    models_performances = {}\n",
    "    models_pred = {}\n",
    "\n",
    "    model_list = set_nn_params(pheno)\n",
    "\n",
    "    for params in model_list:\n",
    "        params_dict = params\n",
    "\n",
    "        learning_rate = params_dict[\"lr\"]\n",
    "        params_dict.pop(\"lr\")\n",
    "\n",
    "        model_name = params_dict[\"model_name\"]\n",
    "        params_dict.pop(\"model_name\")\n",
    "\n",
    "        model = params_dict[\"model\"]\n",
    "        params_dict.pop(\"model\")\n",
    "\n",
    "        # Grid search\n",
    "        models_performances[model_name], models_pred[model_name] = gridsearch(\n",
    "            i, model, run_id, learning_rate, params_dict\n",
    "        )\n",
    "\n",
    "    # Lasso\n",
    "    models_performances[\"lasso\"], models_pred[\"lasso\"] = lasso_train(\n",
    "        train_dataset_classic\n",
    "    )\n",
    "\n",
    "    # save everything to json\n",
    "    write_json(models_performances, json_output_raw)\n",
    "\n",
    "    ######################## ROC AUC compare ########################\n",
    "    overall_y_test = test_dataset.y_data.numpy().ravel()\n",
    "\n",
    "    print(models_pred)\n",
    "    # function returns log10(p-val) thus we take 10**x\n",
    "    p_values = {}\n",
    "    p_values[\"mlp\"] = 10 ** float(\n",
    "        compare_auc_delong_xu.delong_roc_test(\n",
    "            overall_y_test, models_pred[\"lasso\"], models_pred[\"mlp\"].reshape(-1)\n",
    "        )\n",
    "    )\n",
    "    p_values[\"cnn\"] = 10 ** float(\n",
    "        compare_auc_delong_xu.delong_roc_test(\n",
    "            overall_y_test, models_pred[\"lasso\"], models_pred[\"cnn\"].reshape(-1)\n",
    "        )\n",
    "    )\n",
    "    p_values[\"rnn\"] = 10 ** float(\n",
    "        compare_auc_delong_xu.delong_roc_test(\n",
    "            overall_y_test, models_pred[\"lasso\"], models_pred[\"rnn\"].reshape(-1)\n",
    "        )\n",
    "    )\n",
    "    p_values[\"rnn_cnn\"] = 10 ** float(\n",
    "        compare_auc_delong_xu.delong_roc_test(\n",
    "            overall_y_test, models_pred[\"lasso\"], models_pred[\"rnn_cnn\"].reshape(-1)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    cv_p_value_results[i] = p_values\n",
    "    print(cv_current_metics)\n",
    "    ######################## metrics average ########################\n",
    "    metircs_average_prep(cv_current_metics, models_performances)\n",
    "\n",
    "cv_average_metics = metircs_average(cv_current_metics)\n",
    "\n",
    "write_json_2dicts(cv_p_value_results, cv_average_metics, json_output_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d3d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_p_value_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1e5016",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_average_metics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
